{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T02:55:34.299920Z",
     "start_time": "2025-01-28T02:55:27.112786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "from PIL import Image #Transformations from torch vision tend to use PIL images\n",
    "import torch #DeepLearning library for Neural Network\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models #transforms images to correct input for model ##ResNet18##\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "id": "55c5cabe1ebb6239",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T00:02:12.000064Z",
     "start_time": "2025-01-27T00:02:11.991320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import multiprocessing\n",
    "\n",
    "multiprocessing.cpu_count"
   ],
   "id": "b7c4f12df136b7d5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseContext.cpu_count of <multiprocessing.context.DefaultContext object at 0x0000016CD42BBAA0>>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T03:07:24.029074Z",
     "start_time": "2025-01-28T03:07:24.021713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') #if device is available then it will use GPU\n",
    "\n",
    "class PneumoniaDataset(Dataset): #Converts dataset into information used for the model\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir #root dir is simply where the images come from 'images/chest_xray'\n",
    "        self.transform = transform #if transform method is passed then it will use it\n",
    "        self.image_paths = [] #path for each individual image will be saved in list\n",
    "        self.labels = [] #label to go with every image_path will be saved here\n",
    "\n",
    "        for label in ['NORMAL', 'PNEUMONIA']: #chest_xray file is divided into these labels\n",
    "            class_dir = os.path.join(root_dir, label) #will go into the folders with corresponding labeled folder\n",
    "            for img_name in os.listdir(class_dir): # img_name corresponds with image in labeled folded\n",
    "                self.image_paths.append(os.path.join(class_dir, img_name)) #saves path into image_paths list\n",
    "                self.labels.append(0 if label=='NORMAL' else 1) #then saves list into labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths) #important to know dataset length\n",
    "\n",
    "    def __getitem__(self, ind): #will get individual image\n",
    "        img_path = self.image_paths[ind] # gets the image path from the list of image path based on the index provided\n",
    "        image = Image.open(img_path).convert('RGB') #opens image data and converts to RGB\n",
    "        label = self.labels[ind] #label for healthy or pneumonia\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image) #applies transformation parameter passed by user\n",
    "\n",
    "        return image, label"
   ],
   "id": "c2101a8d209d63ce",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T03:07:24.219615Z",
     "start_time": "2025-01-28T03:07:24.213794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#I need to change to torch.nn.Sequential, so I need to transform to tensor in the __getitem__ method above.\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) #These are the values of current weight and\n",
    "    # standard deviation according to Pytorch\n",
    "])"
   ],
   "id": "239ed84c5c6f3225",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T03:07:24.431435Z",
     "start_time": "2025-01-28T03:07:24.401360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = PneumoniaDataset('data/chest_xray/train', transform=transform) #simply saving datasets\n",
    "test_dataset = PneumoniaDataset('data/chest_xray/test', transform=transform)\n",
    "val_dataset = PneumoniaDataset('data/chest_xray/val', transform=transform)"
   ],
   "id": "94494dae9ffc4e1c",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T03:07:24.965654Z",
     "start_time": "2025-01-28T03:07:24.960244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True) #we are creating batches for the models\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ],
   "id": "83d19cc4f04576cc",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T03:07:25.439786Z",
     "start_time": "2025-01-28T03:07:25.262577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1) #Here is how we use existing models for our project\n",
    "model.fc = nn.Linear(model.fc.in_features, 2) #The two will return NORMAL, PNEUMONIA to get two neuron output for our model\n",
    "model = model.to(device)"
   ],
   "id": "3169578a8464506c",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T03:07:26.544097Z",
     "start_time": "2025-01-28T03:07:26.537778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "id": "a0655515502c3022",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T03:18:41.350227Z",
     "start_time": "2025-01-28T03:07:27.364753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}')\n",
    "    model.eval()\n",
    "    val_labels = []\n",
    "    val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs,1)\n",
    "\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "    print('Validation accuracy:', val_accuracy)"
   ],
   "id": "6941e14fe746b286",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.11645766347646713\n",
      "Validation accuracy: 0.8125\n",
      "Epoch 2/10, Loss: 0.06003028526902199\n",
      "Validation accuracy: 0.9375\n",
      "Epoch 3/10, Loss: 0.04217918589711189\n",
      "Validation accuracy: 1.0\n",
      "Epoch 4/10, Loss: 0.05151577666401863\n",
      "Validation accuracy: 0.5625\n",
      "Epoch 5/10, Loss: 0.04119393602013588\n",
      "Validation accuracy: 0.5\n",
      "Epoch 6/10, Loss: 0.0326116643846035\n",
      "Validation accuracy: 0.9375\n",
      "Epoch 7/10, Loss: 0.019765358418226242\n",
      "Validation accuracy: 1.0\n",
      "Epoch 8/10, Loss: 0.029912836849689484\n",
      "Validation accuracy: 0.875\n",
      "Epoch 9/10, Loss: 0.020849233493208885\n",
      "Validation accuracy: 0.875\n",
      "Epoch 10/10, Loss: 0.01964992843568325\n",
      "Validation accuracy: 1.0\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T03:25:17.198723Z",
     "start_time": "2025-01-28T03:25:07.831535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "test_labels = []\n",
    "test_preds = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_preds)\n",
    "print('Test accuracy:', test_accuracy)\n",
    "\n",
    "torch.save(model.state_dict(), 'models/pneumonia_classifier.pth')"
   ],
   "id": "59906f3f0832546d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7964743589743589\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5f2273b19e271a12"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
